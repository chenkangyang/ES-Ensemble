{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/anaconda/envs/gc/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_size = 0.33\n",
    "random_seed = 42\n",
    "cv=5\n",
    "score = 'f1_weighted'\n",
    "max_iteration = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data_four_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pH             float64\n",
      "DO(mg/l)       float64\n",
      "CODMn(mg/l)    float64\n",
      "NH3-N(mg/l)    float64\n",
      "本周水质             int64\n",
      "dtype: object\n",
      "(33612, 5)\n"
     ]
    }
   ],
   "source": [
    "path = os.getcwd()+'/../data/20122018freshwater_four_feature.csv'\n",
    "data_four_features = pd.read_csv(path, na_values = np.nan)\n",
    "\n",
    "print(data_four_features.dtypes)\n",
    "print(data_four_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data_four_features.drop(['本周水质'], axis=1) # Series\n",
    "y = data_four_features['本周水质'] # Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "水质分布情况:\n",
      "1    13272\n",
      "2     8797\n",
      "3     5472\n",
      "0     2438\n",
      "5     2146\n",
      "4     1487\n",
      "Name: 本周水质, dtype: int64\n",
      "\n",
      "各特征类型分布情况:\n",
      "float64    4\n",
      "int64      1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"水质分布情况:\")\n",
    "print(y.value_counts())\n",
    "print(\"\\n各特征类型分布情况:\")\n",
    "print(data_four_features.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert series to ndarray\n",
    "X = X.values\n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                       stratify = y, random_state = random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalize  train data\n",
    "\n",
    "fulfill the Na with median, then standardized the data, output type ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_pipeline = Pipeline([('imputer', preprocessing.Imputer(missing_values='NaN',strategy=\"median\")),\n",
    "                           ('std_scaler', preprocessing.StandardScaler()),])\n",
    "X_train = clean_pipeline.fit_transform(X_train)\n",
    "X_test = clean_pipeline.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST CE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.25, \n",
    "                                       stratify = y_train, random_state = random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/anaconda/envs/gc/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/alex/anaconda/envs/gc/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name: LogisticRegression, valid weighted f1 score:0.135835\n",
      "model_name: LinearDiscriminantAnalysis, valid weighted f1 score:0.169030\n",
      "model_name: SVC, valid weighted f1 score:0.050231\n",
      "model_name: DecisionTreeClassifier, valid weighted f1 score:0.005792\n",
      "model_name: ExtraTreeClassifier, valid weighted f1 score:0.050141\n",
      "model_name: GaussianNB, valid weighted f1 score:0.096223\n",
      "model_name: KNeighborsClassifier, valid weighted f1 score:0.066349\n",
      "model_name: RandomForestClassifier, valid weighted f1 score:0.002107\n",
      "model_name: ExtraTreesClassifier, valid weighted f1 score:0.016389\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    LogisticRegression(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    SVC(probability=True),\n",
    "    DecisionTreeClassifier(),\n",
    "    ExtraTreeClassifier(),\n",
    "    GaussianNB(),\n",
    "    KNeighborsClassifier(),\n",
    "    RandomForestClassifier(random_state=random_seed),\n",
    "    ExtraTreesClassifier(random_state=random_seed)\n",
    "]\n",
    "\n",
    "y_pred_proba_all = []\n",
    "\n",
    "# for model in models:\n",
    "#     model_name = model.__class__.__name__\n",
    "#     model.fit(X_train, y_train)\n",
    "#     y_pred_proba = model.predict_proba(X_valid)\n",
    "#     y_pred = model.predict(X_valid)\n",
    "#     print(\"model_name: %s, valid weighted f1 score:%f\" %(model_name, f1_score(y_valid, y_pred, average=\"weighted\")))\n",
    "#     y_pred_proba_all.append(y_pred_proba)\n",
    "    \n",
    "    \n",
    "i=0\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    with open(\"../pkl/CE_97661/CE_\" + model_name + \".pkl\", \"rb\") as f:\n",
    "        models[i] = pickle.load(f)\n",
    "    y_pred_proba = models[i].predict_proba(X_valid)\n",
    "    y_pred = models[i].predict(X_valid)\n",
    "    print(\"model_name: %s, valid weighted f1 score:%f\" %(model_name, f1_score(y_valid, y_pred, average=\"weighted\")))\n",
    "    y_pred_proba_all.append(y_pred_proba)\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "population_best_weight = np.load(\"../npy/CE_best_weights.npy\")\n",
    "mu = np.load(\"../npy/CE_best_mu.npy\")\n",
    "sigma = np.load(\"../npy/CE_best_sigma.npy\")\n",
    "\n",
    "classifier_num = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "载入的9个模型标签为1-6，而argmax后的标签为0-5，需要加1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/anaconda/envs/gc/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/alex/anaconda/envs/gc/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name: LogisticRegression, test weighted f1 score:0.138406\n",
      "model_name: LinearDiscriminantAnalysis, test weighted f1 score:0.163650\n",
      "model_name: SVC, test weighted f1 score:0.051533\n",
      "model_name: DecisionTreeClassifier, test weighted f1 score:0.019643\n",
      "model_name: ExtraTreeClassifier, test weighted f1 score:0.057417\n",
      "model_name: GaussianNB, test weighted f1 score:0.094210\n",
      "model_name: KNeighborsClassifier, test weighted f1 score:0.065070\n",
      "model_name: RandomForestClassifier, test weighted f1 score:0.016621\n",
      "model_name: ExtraTreesClassifier, test weighted f1 score:0.025582\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9099    0.9939    0.9500       488\n",
      "          1     0.9927    0.9763    0.9844      2655\n",
      "          2     0.9835    0.9801    0.9818      1760\n",
      "          3     0.9779    0.9707    0.9743      1094\n",
      "          4     0.9327    0.9327    0.9327       297\n",
      "          5     0.9593    0.9883    0.9736       429\n",
      "\n",
      "avg / total     0.9771    0.9765    0.9766      6723\n",
      "\n",
      "1 accuaracy: 0.993852\n",
      "2 accuaracy: 0.976271\n",
      "3 accuaracy: 0.980114\n",
      "4 accuaracy: 0.970750\n",
      "5 accuaracy: 0.932660\n",
      "6 accuaracy: 0.988345\n",
      "acc: 0.976498586940354\n",
      "f1_weighted 0.9766169231055404\n"
     ]
    }
   ],
   "source": [
    "y_test_pred_proba_all = []\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    y_test_pred_proba = model.predict_proba(X_test)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    print(\"model_name: %s, test weighted f1 score:%f\" %(model_name, f1_score(y_test, y_test_pred, average=\"weighted\")))\n",
    "    y_test_pred_proba_all.append(y_test_pred_proba)\n",
    "    \n",
    "    \n",
    "y_test_pred_ensemble_proba = np.zeros((len(y_test), 6)) # 集成器概率向量\n",
    "\n",
    "# 为每一个基学习器乘上权重\n",
    "for k in range(classifier_num):\n",
    "    y_test_pred_ensemble_proba += y_test_pred_proba_all[k] * population_best_weight[k]\n",
    "y_test_pred_ensemble = np.argmax(y_test_pred_ensemble_proba, axis=1)+1\n",
    "\n",
    "print(classification_report(y_test, y_test_pred_ensemble, digits=4))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_test_pred_ensemble)\n",
    "i=0\n",
    "acc_all = np.zeros(6)\n",
    "for c in cm:\n",
    "    acc_all[i] = c[i]/np.sum(c)\n",
    "    print(\"%d accuaracy: %f\" %(i+1, acc_all[i]))\n",
    "    i=i+1\n",
    "print(\"acc:\", np.sum(y_test == y_test_pred_ensemble)/y_test_pred_ensemble.shape[0])\n",
    "print('f1_weighted', f1_score(y_test, y_test_pred_ensemble, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

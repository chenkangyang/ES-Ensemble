{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "kf=10\n",
    "score = 'f1_weighted'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### somte sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Smoter(X, y, is_random=False):\n",
    "    if is_random == True:\n",
    "        random_lst = list(np.random.randint(0, 1000, 4))\n",
    "    elif is_random == False:\n",
    "        random_lst = [0] * 4\n",
    "\n",
    "    print(\"rs:\", random_lst)\n",
    "    sm = SMOTE(random_state=random_lst[2], kind = 0.24)\n",
    "    X_smote, y_smote = sm.fit_sample(X, y)\n",
    "\n",
    "    return X_smote, y_smote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data_four_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pH             float64\n",
      "DO(mg/l)       float64\n",
      "CODMn(mg/l)    float64\n",
      "NH3-N(mg/l)    float64\n",
      "本周水质             int64\n",
      "dtype: object\n",
      "(33612, 5)\n"
     ]
    }
   ],
   "source": [
    "path = os.getcwd()+'/../data/20122018freshwater_four_feature.csv'\n",
    "data_four_features = pd.read_csv(path, na_values = np.nan)\n",
    "\n",
    "print(data_four_features.dtypes)\n",
    "print(data_four_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data_four_features.drop(['本周水质'], axis=1) # Series\n",
    "y = data_four_features['本周水质'] # Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "水质分布情况:\n",
      "2    13272\n",
      "3     8797\n",
      "4     5472\n",
      "1     2438\n",
      "6     2146\n",
      "5     1487\n",
      "Name: 本周水质, dtype: int64\n",
      "\n",
      "各特征类型分布情况:\n",
      "float64    4\n",
      "int64      1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"水质分布情况:\")\n",
    "print(y.value_counts())\n",
    "print(\"\\n各特征类型分布情况:\")\n",
    "print(data_four_features.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pH</th>\n",
       "      <th>DO(mg/l)</th>\n",
       "      <th>CODMn(mg/l)</th>\n",
       "      <th>NH3-N(mg/l)</th>\n",
       "      <th>本周水质</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.09</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.33</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.94</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.40</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.20</td>\n",
       "      <td>9.6</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.34</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.80</td>\n",
       "      <td>11.6</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.59</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.64</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pH  DO(mg/l)  CODMn(mg/l)  NH3-N(mg/l)  本周水质\n",
       "0  7.09      10.0          5.7         0.33     3\n",
       "1  6.94      12.0          5.4         0.40     3\n",
       "2  7.20       9.6          4.9         0.34     3\n",
       "3  6.80      11.6          6.3         0.59     4\n",
       "4  6.75      11.0          6.2         0.64     4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_four_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ train_test_split ============\n",
      "67% train: 26889/33612, 33% test: 6723/33612\n"
     ]
    }
   ],
   "source": [
    "print(\"============ train_test_split ============\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                       stratify = y, random_state = random_seed)\n",
    "print(\"67%% train: %d/%d, 33%% test: %d/%d\" %(X_train.shape[0], X.shape[0], X_test.shape[0], X.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalize  train data\n",
    "\n",
    "fulfill the Na with median, then standardized the data, output type ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_pipeline = Pipeline([('imputer', preprocessing.Imputer(missing_values='NaN',strategy=\"median\")),\n",
    "                           ('std_scaler', preprocessing.StandardScaler()),])\n",
    "X_train = clean_pipeline.fit_transform(X_train)\n",
    "X_test = clean_pipeline.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ train_valid_split ============\n"
     ]
    }
   ],
   "source": [
    "print(\"============ train_valid_split ============\")\n",
    "\n",
    "X_train2, X_valid, y_train2, y_valid = train_test_split(X_train, y_train, test_size=0.25, \n",
    "                                       stratify = y_train, random_state = random_seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model selection based on 5 flod cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = [\n",
    "    LogisticRegression(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    LinearSVC(),\n",
    "    DecisionTreeClassifier(),\n",
    "    ExtraTreeClassifier(),\n",
    "    GaussianNB(),\n",
    "    KNeighborsClassifier(),\n",
    "    RandomForestClassifier(random_state=random_seed),\n",
    "    ExtraTreesClassifier(random_state=random_seed),\n",
    "]\n",
    "# CV = 5\n",
    "\n",
    "# entries = []\n",
    "# for model in models:\n",
    "#     model_name = model.__class__.__name__\n",
    "#     accuracies = cross_val_score(model, X_train, y_train, scoring='f1_weighted', cv=CV)\n",
    "#     for fold_idx, accuracy in enumerate(accuracies):\n",
    "#         entries.append((model_name, fold_idx, accuracy))\n",
    "# cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'f1_weighted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(cv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# entries = []\n",
    "# for model in models:\n",
    "#     model_name = model.__class__.__name__\n",
    "#     accuracies = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=CV)\n",
    "#     for fold_idx, accuracy in enumerate(accuracies):\n",
    "#         entries.append((model_name, fold_idx, accuracy))\n",
    "# acc_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(acc_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## metrics on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/anaconda3/envs/gc/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "test_entries = []\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    model.fit(X_train2, y_train2)\n",
    "    y_pred = model.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    test_entries.append((model_name, f1, acc))\n",
    "\n",
    "test_df = pd.DataFrame(test_entries, columns=['model_name', 'f1_weighted', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_test\n",
      "                   model_name  f1_weighted  accuracy\n",
      "0          LogisticRegression     0.620574  0.670980\n",
      "1  LinearDiscriminantAnalysis     0.576099  0.625019\n",
      "2                   LinearSVC     0.587685  0.640042\n",
      "3      DecisionTreeClassifier     0.970106  0.969954\n",
      "4         ExtraTreeClassifier     0.914437  0.914324\n",
      "5                  GaussianNB     0.822296  0.824037\n",
      "6        KNeighborsClassifier     0.897799  0.897813\n",
      "7      RandomForestClassifier     0.976184  0.976052\n",
      "8        ExtraTreesClassifier     0.962632  0.962517\n"
     ]
    }
   ],
   "source": [
    "print(\"model_test\")\n",
    "print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================LogisticRegression=================\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1     0.9333    0.0574    0.1081       488\n",
      "          2     0.6672    0.9951    0.7988      2655\n",
      "          3     0.6628    0.5517    0.6022      1760\n",
      "          4     0.6360    0.4808    0.5476      1094\n",
      "          5     0.0000    0.0000    0.0000       297\n",
      "          6     0.7818    0.8019    0.7917       429\n",
      "\n",
      "avg / total     0.6581    0.6710    0.6206      6723\n",
      "\n",
      "1 accuaracy: 0.057377\n",
      "2 accuaracy: 0.995104\n",
      "3 accuaracy: 0.551705\n",
      "4 accuaracy: 0.480804\n",
      "5 accuaracy: 0.000000\n",
      "6 accuaracy: 0.801865\n",
      "acc: 0.6709802171649561\n",
      "f1_weighted 0.6205742071342153\n",
      "=================LinearDiscriminantAnalysis=================\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1     0.0000    0.0000    0.0000       488\n",
      "          2     0.6016    0.9992    0.7510      2655\n",
      "          3     0.6036    0.3858    0.4707      1760\n",
      "          4     0.7075    0.5283    0.6049      1094\n",
      "          5     0.5361    0.2997    0.3844       297\n",
      "          6     0.9902    0.4732    0.6404       429\n",
      "\n",
      "avg / total     0.5976    0.6250    0.5761      6723\n",
      "\n",
      "1 accuaracy: 0.000000\n",
      "2 accuaracy: 0.999247\n",
      "3 accuaracy: 0.385795\n",
      "4 accuaracy: 0.528336\n",
      "5 accuaracy: 0.299663\n",
      "6 accuaracy: 0.473193\n",
      "acc: 0.6250185928900789\n",
      "f1_weighted 0.5760985004006811\n",
      "=================LinearSVC=================\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1     0.9322    0.1127    0.2011       488\n",
      "          2     0.6385    0.9985    0.7789      2655\n",
      "          3     0.6200    0.4199    0.5007      1760\n",
      "          4     0.6106    0.4616    0.5258      1094\n",
      "          5     0.0000    0.0000    0.0000       297\n",
      "          6     0.7160    0.8228    0.7657       429\n",
      "\n",
      "avg / total     0.6272    0.6400    0.5877      6723\n",
      "\n",
      "1 accuaracy: 0.112705\n",
      "2 accuaracy: 0.998493\n",
      "3 accuaracy: 0.419886\n",
      "4 accuaracy: 0.461609\n",
      "5 accuaracy: 0.000000\n",
      "6 accuaracy: 0.822844\n",
      "acc: 0.6400416480737766\n",
      "f1_weighted 0.5876847762600284\n",
      "=================DecisionTreeClassifier=================\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1     0.8944    0.9898    0.9397       488\n",
      "          2     0.9874    0.9702    0.9787      2655\n",
      "          3     0.9783    0.9722    0.9752      1760\n",
      "          4     0.9742    0.9653    0.9697      1094\n",
      "          5     0.9158    0.9158    0.9158       297\n",
      "          6     0.9527    0.9860    0.9691       429\n",
      "\n",
      "avg / total     0.9707    0.9700    0.9701      6723\n",
      "\n",
      "1 accuaracy: 0.989754\n",
      "2 accuaracy: 0.970245\n",
      "3 accuaracy: 0.972159\n",
      "4 accuaracy: 0.965265\n",
      "5 accuaracy: 0.915825\n",
      "6 accuaracy: 0.986014\n",
      "acc: 0.9699538896326045\n",
      "f1_weighted 0.9701060258304468\n",
      "=================ExtraTreeClassifier=================\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1     0.8553    0.9324    0.8922       488\n",
      "          2     0.9590    0.9435    0.9512      2655\n",
      "          3     0.9102    0.9159    0.9131      1760\n",
      "          4     0.8887    0.8757    0.8821      1094\n",
      "          5     0.7483    0.7407    0.7445       297\n",
      "          6     0.9106    0.9254    0.9179       429\n",
      "\n",
      "avg / total     0.9149    0.9143    0.9144      6723\n",
      "\n",
      "1 accuaracy: 0.932377\n",
      "2 accuaracy: 0.943503\n",
      "3 accuaracy: 0.915909\n",
      "4 accuaracy: 0.875686\n",
      "5 accuaracy: 0.740741\n",
      "6 accuaracy: 0.925408\n",
      "acc: 0.9143239625167336\n",
      "f1_weighted 0.9144374219454501\n",
      "=================GaussianNB=================\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1     0.7886    0.7951    0.7918       488\n",
      "          2     0.8657    0.9081    0.8864      2655\n",
      "          3     0.7909    0.8403    0.8149      1760\n",
      "          4     0.7816    0.7130    0.7457      1094\n",
      "          5     0.6560    0.5522    0.5996       297\n",
      "          6     0.9695    0.7413    0.8402       429\n",
      "\n",
      "avg / total     0.8242    0.8240    0.8223      6723\n",
      "\n",
      "1 accuaracy: 0.795082\n",
      "2 accuaracy: 0.908098\n",
      "3 accuaracy: 0.840341\n",
      "4 accuaracy: 0.712980\n",
      "5 accuaracy: 0.552189\n",
      "6 accuaracy: 0.741259\n",
      "acc: 0.8240368882939164\n",
      "f1_weighted 0.8222958869396308\n",
      "=================KNeighborsClassifier=================\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1     0.7530    0.7684    0.7606       488\n",
      "          2     0.9016    0.9315    0.9163      2655\n",
      "          3     0.9135    0.8875    0.9003      1760\n",
      "          4     0.9245    0.8958    0.9099      1094\n",
      "          5     0.8467    0.8182    0.8322       297\n",
      "          6     0.9482    0.9394    0.9438       429\n",
      "\n",
      "avg / total     0.8982    0.8978    0.8978      6723\n",
      "\n",
      "1 accuaracy: 0.768443\n",
      "2 accuaracy: 0.931450\n",
      "3 accuaracy: 0.887500\n",
      "4 accuaracy: 0.895795\n",
      "5 accuaracy: 0.818182\n",
      "6 accuaracy: 0.939394\n",
      "acc: 0.8978134761267291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/anaconda3/envs/gc/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/alex/anaconda3/envs/gc/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_weighted 0.8977994538909129\n",
      "=================RandomForestClassifier=================\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1     0.9065    0.9939    0.9482       488\n",
      "          2     0.9927    0.9755    0.9840      2655\n",
      "          3     0.9835    0.9801    0.9818      1760\n",
      "          4     0.9779    0.9698    0.9738      1094\n",
      "          5     0.9295    0.9327    0.9311       297\n",
      "          6     0.9593    0.9883    0.9736       429\n",
      "\n",
      "avg / total     0.9767    0.9761    0.9762      6723\n",
      "\n",
      "1 accuaracy: 0.993852\n",
      "2 accuaracy: 0.975518\n",
      "3 accuaracy: 0.980114\n",
      "4 accuaracy: 0.969835\n",
      "5 accuaracy: 0.932660\n",
      "6 accuaracy: 0.988345\n",
      "acc: 0.976052357578462\n",
      "f1_weighted 0.9761838790295564\n",
      "=================ExtraTreesClassifier=================\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1     0.8905    0.9836    0.9348       488\n",
      "          2     0.9803    0.9721    0.9762      2655\n",
      "          3     0.9710    0.9528    0.9619      1760\n",
      "          4     0.9506    0.9497    0.9502      1094\n",
      "          5     0.9189    0.9158    0.9174       297\n",
      "          6     0.9701    0.9837    0.9769       429\n",
      "\n",
      "avg / total     0.9631    0.9625    0.9626      6723\n",
      "\n",
      "1 accuaracy: 0.983607\n",
      "2 accuaracy: 0.972128\n",
      "3 accuaracy: 0.952841\n",
      "4 accuaracy: 0.949726\n",
      "5 accuaracy: 0.915825\n",
      "6 accuaracy: 0.983683\n",
      "acc: 0.9625167336010709\n",
      "f1_weighted 0.9626320618704984\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"=================\" + model_name + \"=================\")\n",
    "    print(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    i=0\n",
    "    acc_all = np.zeros(6)\n",
    "    for c in cm:\n",
    "        acc_all[i] = c[i]/np.sum(c)\n",
    "        print(\"%d accuaracy: %f\" %(i+1, acc_all[i]))\n",
    "        i=i+1\n",
    "    print(\"acc:\", np.sum(y_test == y_pred)/y_pred.shape[0])\n",
    "    print('f1_weighted', f1_score(y_test, y_pred, average='weighted'))\n",
    "    \n",
    "        \n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "#     print((model_name, f1, acc, acc_all[5]))\n",
    "    test_entries.append((model_name, f1, acc, acc_all[5]))\n",
    "\n",
    "test_df = pd.DataFrame(test_entries, columns=['model_name', 'f1_weighted', 'accuracy', \"6_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>6_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.620574</td>\n",
       "      <td>0.670980</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.576099</td>\n",
       "      <td>0.625019</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.587685</td>\n",
       "      <td>0.640042</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.970106</td>\n",
       "      <td>0.969954</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "      <td>0.914437</td>\n",
       "      <td>0.914324</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.822296</td>\n",
       "      <td>0.824037</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.897799</td>\n",
       "      <td>0.897813</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.976184</td>\n",
       "      <td>0.976052</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.962632</td>\n",
       "      <td>0.962517</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.620574</td>\n",
       "      <td>0.670980</td>\n",
       "      <td>0.801865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.576099</td>\n",
       "      <td>0.625019</td>\n",
       "      <td>0.473193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.587685</td>\n",
       "      <td>0.640042</td>\n",
       "      <td>0.822844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.970106</td>\n",
       "      <td>0.969954</td>\n",
       "      <td>0.986014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "      <td>0.914437</td>\n",
       "      <td>0.914324</td>\n",
       "      <td>0.925408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.822296</td>\n",
       "      <td>0.824037</td>\n",
       "      <td>0.741259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.897799</td>\n",
       "      <td>0.897813</td>\n",
       "      <td>0.939394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.976184</td>\n",
       "      <td>0.976052</td>\n",
       "      <td>0.988345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.962632</td>\n",
       "      <td>0.962517</td>\n",
       "      <td>0.983683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model_name  f1_weighted  accuracy  6_accuracy\n",
       "0           LogisticRegression     0.620574  0.670980         NaN\n",
       "1   LinearDiscriminantAnalysis     0.576099  0.625019         NaN\n",
       "2                    LinearSVC     0.587685  0.640042         NaN\n",
       "3       DecisionTreeClassifier     0.970106  0.969954         NaN\n",
       "4          ExtraTreeClassifier     0.914437  0.914324         NaN\n",
       "5                   GaussianNB     0.822296  0.824037         NaN\n",
       "6         KNeighborsClassifier     0.897799  0.897813         NaN\n",
       "7       RandomForestClassifier     0.976184  0.976052         NaN\n",
       "8         ExtraTreesClassifier     0.962632  0.962517         NaN\n",
       "9           LogisticRegression     0.620574  0.670980    0.801865\n",
       "10  LinearDiscriminantAnalysis     0.576099  0.625019    0.473193\n",
       "11                   LinearSVC     0.587685  0.640042    0.822844\n",
       "12      DecisionTreeClassifier     0.970106  0.969954    0.986014\n",
       "13         ExtraTreeClassifier     0.914437  0.914324    0.925408\n",
       "14                  GaussianNB     0.822296  0.824037    0.741259\n",
       "15        KNeighborsClassifier     0.897799  0.897813    0.939394\n",
       "16      RandomForestClassifier     0.976184  0.976052    0.988345\n",
       "17        ExtraTreesClassifier     0.962632  0.962517    0.983683"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

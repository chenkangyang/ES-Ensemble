{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "\n",
    "import pickle\n",
    "import argparse\n",
    "# from gcforest.gcforest import GCForest\n",
    "# gc = GCForest(config) # should be a dict\n",
    "# X_train_enc = gc.fit_transform(X_train, y_train)\n",
    "# y_pred = gc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data and Question of Interest\n",
    "\n",
    "Let's take a look at the [UCI Adult Data Set](https://archive.ics.uci.edu/ml/datasets/adult). This data set was extrated from Census data with the goal of prediction who makes over $50,000.\n",
    "\n",
    "I would like to use these data as a means of exploring various machine learning algorithms that will increase in complexity to see how the compare on various evaluation metrics. Additonally, it will be interesting to see how much there is to gain by spending some time fine-tuning these algorithms.\n",
    "\n",
    "We will look at the following algorithms:\n",
    "1. [Logistic Regression](http://learningwithdata.com/logistic-regression-and-optimization.html#logistic-regression-and-optimization)\n",
    "2. [Gradient Boosting Trees](https://machinelearningmastery.com/gentle-introduction-gradient-boosting-algorithm-machine-learning/)\n",
    "3. [Deep Learning](https://blog.algorithmia.com/introduction-to-deep-learning-2016/)\n",
    "\n",
    "And evaluate them with the following metrics:\n",
    "1. [F1 Score](https://en.wikipedia.org/wiki/F1_score)\n",
    "2. [Area Under ROC Curve](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)\n",
    "3. [Accuracy](https://www.cs.cornell.edu/courses/cs578/2003fa/performance_measures.pdf)\n",
    "\n",
    "Let's go ahead and read in the data and take a look."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 载入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = ['age', 'workclass', 'fnlwgt', 'education', 'educationnum', 'maritalstatus', 'occupation', 'relationship', 'race',\n",
    "        'sex', 'capitalgain', 'capitalloss', 'hoursperweek', 'nativecountry', 'label']\n",
    "train_df = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\",\n",
    "                      header=None, names=names)\n",
    "test_df = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\",\n",
    "                      header=None, names=names, skiprows=[0])\n",
    "all_df = pd.concat([train_df, test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educationnum</th>\n",
       "      <th>maritalstatus</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capitalgain</th>\n",
       "      <th>capitalloss</th>\n",
       "      <th>hoursperweek</th>\n",
       "      <th>nativecountry</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  educationnum  \\\n",
       "0   39          State-gov   77516   Bachelors            13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors            13   \n",
       "2   38            Private  215646     HS-grad             9   \n",
       "3   53            Private  234721        11th             7   \n",
       "4   28            Private  338409   Bachelors            13   \n",
       "\n",
       "         maritalstatus          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capitalgain  capitalloss  hoursperweek   nativecountry   label  \n",
       "0         2174            0            40   United-States   <=50K  \n",
       "1            0            0            13   United-States   <=50K  \n",
       "2            0            0            40   United-States   <=50K  \n",
       "3            0            0            40   United-States   <=50K  \n",
       "4            0            0            40            Cuba   <=50K  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all_df.to_csv('../data/adult/all_df.csv', encoding='utf-8', index=False)\n",
    "# train_df.to_csv('../data/adult/train.csv', encoding='utf-8', index=False)\n",
    "# test_df.to_csv('../data/adult/test.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48842, 15)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征工程\n",
    "\n",
    "\n",
    "It looks like we have 14 columns to help us predict our classification. We will drop fnlwgt and education and then convert our categorical features to dummy variables. We will also convert our label to 0 and 1 where 1 means the person made more than $50k\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drop_columns = ['fnlwgt', 'education']\n",
    "continuous_features = ['age', 'capitalgain', 'capitalloss', 'hoursperweek']\n",
    "cat_features =['educationnum', 'workclass', 'maritalstatus', 'occupation', 'relationship', 'race', 'sex', 'nativecountry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_df_dummies = pd.get_dummies(all_df, columns=cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_df_dummies.drop(drop_columns, 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = all_df_dummies['label'].apply(lambda x: 0 if '<' in x else 1)\n",
    "X = all_df_dummies.drop(['label'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.760718\n",
       "1    0.239282\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32724, 106)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " # 中位数填充特征值后，将数据标准化\n",
    "clean_pipeline = Pipeline([('imputer', preprocessing.Imputer(strategy=\"median\")),\n",
    "                           ('std_scaler', preprocessing.StandardScaler()),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_clean = clean_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_clean = clean_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "评估函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(true, pred):\n",
    "    f1 = metrics.f1_score(true, pred)\n",
    "    roc_auc = metrics.roc_auc_score(true, pred)\n",
    "    accuracy = metrics.accuracy_score(true, pred)\n",
    "    print(\"F1: {0}\\nROC_AUC: {1}\\nACCURACY: {2}\".format(f1, roc_auc, accuracy))\n",
    "    return f1, roc_auc, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "The first model up is a simple logistic regression with the default hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.6530320366132722\n",
      "ROC_AUC: 0.7590740874725979\n",
      "ACCURACY: 0.8494850477726765\n"
     ]
    }
   ],
   "source": [
    "lr_f1, lr_roc_auc, lr_acc = evaluate(y_test, lr_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GcForest\n",
    "\n",
    "The second model up is a gcforest with our hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "If you wish to use Cascade Layer only, the legal data type for X_train, X_test can be:\n",
    "\n",
    "    2-D numpy array of shape (n_sampels, n_features).\n",
    "    3-D or 4-D numpy array are also acceptable. For example, passing X_train of shape (60000, 28, 28) or (60000,3,28,28) will be automatically be reshape into (60000, 784)/(60000,2352).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"..\") \n",
    "from gcforest.gcforest import GCForest\n",
    "from gcforest.utils.config_utils import load_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--model\", dest=\"model\", type=str, default=None, help=\"gcfoest Net Model File\")\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "def get_toy_config():\n",
    "    config = {}\n",
    "    ca_config = {}\n",
    "    ca_config[\"random_state\"] = 0\n",
    "    ca_config[\"max_layers\"] = 10\n",
    "    ca_config[\"early_stopping_rounds\"] = 3\n",
    "    ca_config[\"n_classes\"] = 2\n",
    "    ca_config[\"estimators\"] = []\n",
    "#     ca_config[\"estimators\"].append(\n",
    "#             {\"n_folds\": 5, \"type\": \"XGBClassifier\", \"n_estimators\": 10, \"max_depth\": 5,\n",
    "#              \"objective\": \"multi:softprob\", \"silent\": True, \"nthread\": -1, \"learning_rate\": 0.1} )\n",
    "    ca_config[\"estimators\"].append({\"n_folds\": 5, \"type\": \"RandomForestClassifier\", \"n_estimators\": 10, \"max_depth\": None, \"n_jobs\": -1})\n",
    "    ca_config[\"estimators\"].append({\"n_folds\": 5, \"type\": \"ExtraTreesClassifier\", \"n_estimators\": 10, \"max_depth\": None, \"n_jobs\": -1})\n",
    "    ca_config[\"estimators\"].append({\"n_folds\": 5, \"type\": \"LogisticRegression\"})\n",
    "    config[\"cascade\"] = ca_config\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-10-03 00:10:27,814][cascade_classifier.fit_transform] X_groups_train.shape=[(32724, 106)],y_train.shape=(32724,),X_groups_test.shape=no_test,y_test.shape=no_test\n",
      "[ 2018-10-03 00:10:27,856][cascade_classifier.fit_transform] group_dims=[106]\n",
      "[ 2018-10-03 00:10:27,858][cascade_classifier.fit_transform] group_starts=[0]\n",
      "[ 2018-10-03 00:10:27,861][cascade_classifier.fit_transform] group_ends=[106]\n",
      "[ 2018-10-03 00:10:27,864][cascade_classifier.fit_transform] X_train.shape=(32724, 106),X_test.shape=(0, 106)\n",
      "[ 2018-10-03 00:10:27,903][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(32724, 106), X_cur_test.shape=(0, 106)\n",
      "[ 2018-10-03 00:10:28,369][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 5_folds.train_0.predict)=84.28%\n",
      "[ 2018-10-03 00:10:28,720][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 5_folds.train_1.predict)=84.83%\n",
      "[ 2018-10-03 00:10:29,059][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 5_folds.train_2.predict)=83.71%\n",
      "[ 2018-10-03 00:10:29,410][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 5_folds.train_3.predict)=84.20%\n",
      "[ 2018-10-03 00:10:29,751][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 5_folds.train_4.predict)=84.73%\n",
      "[ 2018-10-03 00:10:29,756][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 5_folds.train_cv.predict)=84.35%\n",
      "[ 2018-10-03 00:10:30,229][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 5_folds.train_0.predict)=82.63%\n",
      "[ 2018-10-03 00:10:30,683][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 5_folds.train_1.predict)=82.06%\n",
      "[ 2018-10-03 00:10:31,137][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 5_folds.train_2.predict)=82.93%\n",
      "[ 2018-10-03 00:10:31,576][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 5_folds.train_3.predict)=82.53%\n",
      "[ 2018-10-03 00:10:32,021][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 5_folds.train_4.predict)=82.17%\n",
      "[ 2018-10-03 00:10:32,023][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 5_folds.train_cv.predict)=82.47%\n",
      "[ 2018-10-03 00:10:32,278][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 5_folds.train_0.predict)=85.32%\n",
      "[ 2018-10-03 00:10:32,471][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 5_folds.train_1.predict)=84.98%\n",
      "[ 2018-10-03 00:10:32,658][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 5_folds.train_2.predict)=85.67%\n",
      "[ 2018-10-03 00:10:32,828][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 5_folds.train_3.predict)=84.54%\n",
      "[ 2018-10-03 00:10:33,002][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 5_folds.train_4.predict)=85.48%\n",
      "[ 2018-10-03 00:10:33,004][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 5_folds.train_cv.predict)=85.20%\n",
      "[ 2018-10-03 00:10:33,006][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=84.77%\n",
      "[ 2018-10-03 00:10:33,029][cascade_classifier.fit_transform] [layer=1] look_indexs=[0], X_cur_train.shape=(32724, 112), X_cur_test.shape=(0, 112)\n",
      "[ 2018-10-03 00:10:33,382][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 5_folds.train_0.predict)=85.04%\n",
      "[ 2018-10-03 00:10:33,722][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 5_folds.train_1.predict)=86.14%\n",
      "[ 2018-10-03 00:10:34,068][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 5_folds.train_2.predict)=85.93%\n",
      "[ 2018-10-03 00:10:34,425][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 5_folds.train_3.predict)=85.83%\n",
      "[ 2018-10-03 00:10:34,786][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 5_folds.train_4.predict)=85.57%\n",
      "[ 2018-10-03 00:10:34,789][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 5_folds.train_cv.predict)=85.70%\n",
      "[ 2018-10-03 00:10:35,270][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 5_folds.train_0.predict)=85.37%\n",
      "[ 2018-10-03 00:10:35,624][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 5_folds.train_1.predict)=85.24%\n",
      "[ 2018-10-03 00:10:36,086][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 5_folds.train_2.predict)=86.43%\n",
      "[ 2018-10-03 00:10:36,533][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 5_folds.train_3.predict)=85.48%\n",
      "[ 2018-10-03 00:10:36,977][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 5_folds.train_4.predict)=85.12%\n",
      "[ 2018-10-03 00:10:36,979][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 5_folds.train_cv.predict)=85.53%\n",
      "[ 2018-10-03 00:10:37,372][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 5_folds.train_0.predict)=85.50%\n",
      "[ 2018-10-03 00:10:37,581][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 5_folds.train_1.predict)=85.84%\n",
      "[ 2018-10-03 00:10:37,788][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 5_folds.train_2.predict)=85.88%\n",
      "[ 2018-10-03 00:10:38,047][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 5_folds.train_3.predict)=84.87%\n",
      "[ 2018-10-03 00:10:38,316][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 5_folds.train_4.predict)=85.65%\n",
      "[ 2018-10-03 00:10:38,340][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 5_folds.train_cv.predict)=85.55%\n",
      "[ 2018-10-03 00:10:38,344][cascade_classifier.calc_accuracy] Accuracy(layer_1 - train.classifier_average)=86.38%\n",
      "[ 2018-10-03 00:10:38,355][cascade_classifier.fit_transform] [layer=2] look_indexs=[0], X_cur_train.shape=(32724, 112), X_cur_test.shape=(0, 112)\n",
      "[ 2018-10-03 00:10:38,719][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 5_folds.train_0.predict)=85.95%\n",
      "[ 2018-10-03 00:10:39,063][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 5_folds.train_1.predict)=85.30%\n",
      "[ 2018-10-03 00:10:39,421][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 5_folds.train_2.predict)=85.07%\n",
      "[ 2018-10-03 00:10:39,764][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 5_folds.train_3.predict)=84.81%\n",
      "[ 2018-10-03 00:10:40,112][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 5_folds.train_4.predict)=85.57%\n",
      "[ 2018-10-03 00:10:40,115][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 5_folds.train_cv.predict)=85.34%\n",
      "[ 2018-10-03 00:10:40,681][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 5_folds.train_0.predict)=84.98%\n",
      "[ 2018-10-03 00:10:41,237][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 5_folds.train_1.predict)=84.64%\n",
      "[ 2018-10-03 00:10:41,894][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 5_folds.train_2.predict)=85.27%\n",
      "[ 2018-10-03 00:10:42,444][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 5_folds.train_3.predict)=84.29%\n",
      "[ 2018-10-03 00:10:43,005][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 5_folds.train_4.predict)=85.10%\n",
      "[ 2018-10-03 00:10:43,007][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 5_folds.train_cv.predict)=84.86%\n",
      "[ 2018-10-03 00:10:43,357][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 5_folds.train_0.predict)=85.95%\n",
      "[ 2018-10-03 00:10:43,808][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 5_folds.train_1.predict)=86.48%\n",
      "[ 2018-10-03 00:10:44,202][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 5_folds.train_2.predict)=86.69%\n",
      "[ 2018-10-03 00:10:44,806][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 5_folds.train_3.predict)=86.06%\n",
      "[ 2018-10-03 00:10:45,227][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 5_folds.train_4.predict)=85.93%\n",
      "[ 2018-10-03 00:10:45,229][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 5_folds.train_cv.predict)=86.22%\n",
      "[ 2018-10-03 00:10:45,237][cascade_classifier.calc_accuracy] Accuracy(layer_2 - train.classifier_average)=86.07%\n",
      "[ 2018-10-03 00:10:45,256][cascade_classifier.fit_transform] [layer=3] look_indexs=[0], X_cur_train.shape=(32724, 112), X_cur_test.shape=(0, 112)\n",
      "[ 2018-10-03 00:10:45,623][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 5_folds.train_0.predict)=86.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-10-03 00:10:45,968][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 5_folds.train_1.predict)=85.68%\n",
      "[ 2018-10-03 00:10:46,326][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 5_folds.train_2.predict)=85.10%\n",
      "[ 2018-10-03 00:10:46,667][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 5_folds.train_3.predict)=85.88%\n",
      "[ 2018-10-03 00:10:47,008][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 5_folds.train_4.predict)=85.42%\n",
      "[ 2018-10-03 00:10:47,013][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 5_folds.train_cv.predict)=85.68%\n",
      "[ 2018-10-03 00:10:47,371][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 5_folds.train_0.predict)=84.63%\n",
      "[ 2018-10-03 00:10:47,812][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 5_folds.train_1.predict)=84.74%\n",
      "[ 2018-10-03 00:10:48,365][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 5_folds.train_2.predict)=85.56%\n",
      "[ 2018-10-03 00:10:48,710][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 5_folds.train_3.predict)=85.44%\n",
      "[ 2018-10-03 00:10:49,050][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 5_folds.train_4.predict)=84.89%\n",
      "[ 2018-10-03 00:10:49,052][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 5_folds.train_cv.predict)=85.05%\n",
      "[ 2018-10-03 00:10:49,379][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 5_folds.train_0.predict)=86.98%\n",
      "[ 2018-10-03 00:10:49,608][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 5_folds.train_1.predict)=85.84%\n",
      "[ 2018-10-03 00:10:49,863][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 5_folds.train_2.predict)=86.10%\n",
      "[ 2018-10-03 00:10:50,168][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 5_folds.train_3.predict)=86.31%\n",
      "[ 2018-10-03 00:10:50,372][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 5_folds.train_4.predict)=85.99%\n",
      "[ 2018-10-03 00:10:50,373][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 5_folds.train_cv.predict)=86.24%\n",
      "[ 2018-10-03 00:10:50,377][cascade_classifier.calc_accuracy] Accuracy(layer_3 - train.classifier_average)=86.10%\n",
      "[ 2018-10-03 00:10:50,387][cascade_classifier.fit_transform] [layer=4] look_indexs=[0], X_cur_train.shape=(32724, 112), X_cur_test.shape=(0, 112)\n",
      "[ 2018-10-03 00:10:50,752][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 5_folds.train_0.predict)=85.33%\n",
      "[ 2018-10-03 00:10:51,107][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 5_folds.train_1.predict)=85.68%\n",
      "[ 2018-10-03 00:10:51,454][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 5_folds.train_2.predict)=85.67%\n",
      "[ 2018-10-03 00:10:51,798][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 5_folds.train_3.predict)=85.74%\n",
      "[ 2018-10-03 00:10:52,269][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 5_folds.train_4.predict)=85.39%\n",
      "[ 2018-10-03 00:10:52,273][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 5_folds.train_cv.predict)=85.56%\n",
      "[ 2018-10-03 00:10:52,963][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 5_folds.train_0.predict)=85.69%\n",
      "[ 2018-10-03 00:10:53,725][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 5_folds.train_1.predict)=85.12%\n",
      "[ 2018-10-03 00:10:54,179][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 5_folds.train_2.predict)=85.74%\n",
      "[ 2018-10-03 00:10:54,625][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 5_folds.train_3.predict)=85.31%\n",
      "[ 2018-10-03 00:10:55,060][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 5_folds.train_4.predict)=84.93%\n",
      "[ 2018-10-03 00:10:55,062][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 5_folds.train_cv.predict)=85.36%\n",
      "[ 2018-10-03 00:10:55,293][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 5_folds.train_0.predict)=86.68%\n",
      "[ 2018-10-03 00:10:55,604][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 5_folds.train_1.predict)=85.99%\n",
      "[ 2018-10-03 00:10:55,899][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 5_folds.train_2.predict)=86.33%\n",
      "[ 2018-10-03 00:10:56,169][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 5_folds.train_3.predict)=85.93%\n",
      "[ 2018-10-03 00:10:56,484][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 5_folds.train_4.predict)=85.67%\n",
      "[ 2018-10-03 00:10:56,486][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 5_folds.train_cv.predict)=86.12%\n",
      "[ 2018-10-03 00:10:56,489][cascade_classifier.calc_accuracy] Accuracy(layer_4 - train.classifier_average)=86.25%\n",
      "[ 2018-10-03 00:10:56,490][cascade_classifier.fit_transform] [Result][Optimal Level Detected] opt_layer_num=2, accuracy_train=86.38%, accuracy_test=0.00%\n",
      "[ 2018-10-03 00:10:56,534][cascade_classifier.transform] X_groups_test.shape=[(16118, 106)]\n",
      "[ 2018-10-03 00:10:56,546][cascade_classifier.transform] group_dims=[106]\n",
      "[ 2018-10-03 00:10:56,547][cascade_classifier.transform] X_test.shape=(16118, 106)\n",
      "[ 2018-10-03 00:10:56,558][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(16118, 106)\n",
      "[ 2018-10-03 00:10:57,683][cascade_classifier.transform] [layer=1] look_indexs=[0], X_cur_test.shape=(16118, 112)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.6708607377752358\n",
      "ROC_AUC: 0.7696213007722407\n",
      "ACCURACY: 0.8571783099640153\n"
     ]
    }
   ],
   "source": [
    "config = get_toy_config()\n",
    "gc = GCForest(config)\n",
    "\n",
    "# If the model you use cost too much memory for you.\n",
    "# You can use these methods to force gcforest not keeping model in memory\n",
    "# gc.set_keep_model_in_mem(False), default is TRUE.\n",
    "\n",
    "X_train_enc = gc.fit_transform(X_train, y_train)\n",
    "y_pred = gc.predict(X_test)\n",
    "gc_f1, gc_roc_auc, gc_acc = evaluate(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gc]",
   "language": "python",
   "name": "conda-env-gc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
